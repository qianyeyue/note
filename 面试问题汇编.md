

# 面试问题汇编

[TOC]



## 个人信息所带来的问题

### 关于美国全球中学生数学建模大赛的问题

##### 1.数学理论与模型的建立

###### 问题：怎么建立数学理论与模型？

回答:   根据数学建模的目的和问题的背景做出必要的简化假设，用字母表示未知量，利用相应的物理或其他规律列出数学式子，做出数学上的解答，用这个答案解释这个问题

模型准备->模型假设->模型构成->模型求解->模型分析->模型检验->模型应用

###### 问题：运用了哪些模型？

静态和动态模型：系统各量之间的关系是不随时间的变化而变化的，一般都用代数方程来表达。动态模型是指描述系统各量之间随时间变化而变化的规律的数学表达式

线性模型 　线性模型中各量之间的关系是线性的，可以应用叠加原理，即几个不同的输入量同时作用于系统的响应，等于几个输入量单独作用的响应之和

##### 2.matlab有关知识

###### 问题：matlab是什么？

回答：MATLAB是一种用于技术计算的高性能语言。它在一个易于使用的环境中集成了计算，[可视化](https://so.csdn.net/so/search?q=可视化&spm=1001.2101.3001.7020)和编程，其中问题和解决方案以熟悉的数学符号表示，可以用于1.数学和计算4.数据分析，探索和可视化等

###### 问题：学了哪些matlab的知识？

- 画图函数。例如plot，stairs，mesh等等。
- 输出函数。例如fprintf，disp，fopen，fwrite等等。随机函数。例如rand，randn等等
- 统计函数。例如sum，min，max，mean等等。
- 矩阵的运算公式
- 创建矩阵代码	意义
  []	空阵（matlab允许输入空阵，当一项操作无结果时，返回空阵）
  ones(M, N)	全部元素都为1的矩阵
  zeros(M, N)	全部元素都为0的矩阵
  rand(M, N)	在[0,1]均匀分布的随机矩阵
  randn(M, N)	在[0,1]正态分布的随机矩阵
  eye(N)	单位矩阵
  randperm(n)	创建一个含n个[1~n]整数的随机向量
- 一些基本操作
- size——矩阵的大小
- length——向量长度
- ndims——矩阵维数(1，2，3)
- disp——显示矩阵或文字
- inv——求逆
- det——行列式

矩阵的加法、乘法
矩阵加法的基本形式为X ± Y ，X , Y ，X,Y必须是同维的矩阵，否则将会给出错误信息。

>> x = [1, 2; 3, 4];  %矩阵的表示1
>> y = [1 2; 3 4];    %矩阵的表示2
>> 1
>> 2
>> 矩阵乘法则两个矩阵必须满足矩阵相乘的条件。
>> 特殊情况：一个矩阵乘以一个数（1 × 1 1 \times 11×1的矩阵）视作矩阵的数乘。

利用其中的画图函数画图，随机函数生成大量的数，并把这些数连成曲线画出来，用于我们小组的数据检验

### 关于勤创二面

##### 1.前端有关知识，完成了前端部分

###### 问题：前端的哪些知识？

比如

HTML语言（超文本标记语言）

它包括一系列[标签](https://baike.baidu.com/item/标签/2440469?fromModule=lemma_inlink)．通过这些标签可以将网络上的[文档](https://baike.baidu.com/item/文档/1009768?fromModule=lemma_inlink)格式统一，使分散的[Internet](https://baike.baidu.com/item/Internet/272794?fromModule=lemma_inlink)资源连接为一个逻辑整体（构成网页界面的主体存放在.html文件）

关键词：标签，格式统一

CSS语言（对网页上的内容进行修饰，存放在.css文件中）层叠样式表(英文全称：Cascading Style Sheets)是一种用来表现[HTML](https://baike.baidu.com/item/HTML?fromModule=lemma_inlink)（[标准通用标记语言](https://baike.baidu.com/item/标准通用标记语言/6805073?fromModule=lemma_inlink)的一个应用）等文件样式的计算机语言

关键词：修饰

Js语言（存放在.js文件中）一种编程语言，作为开发[Web](https://baike.baidu.com/item/Web/150564?fromModule=lemma_inlink)页面的脚本语言

关键词：脚本语言

### 个人陈述部分

#### 1.软件工程专业导论

###### 问题：讲了什么？

软件开发模型

##### 软件开发模型有哪些

###### 瀑布模型

　　瀑布模型将[软件生命周期](https://wiki.mbalib.com/wiki/软件生命周期)划分为制定计划、需求分析、软件设计、程序编写、[软件测试](https://wiki.mbalib.com/wiki/软件测试)和运行维护等六个基本活动，并且规定了它们自上而下、相互衔接的固定次序，如同瀑布流水，逐级下落。

　　在瀑布模型中，软件开发的各项活动严格按照线性方式进行，当前活动接受上一项活动的工作结果，实施完成所需的工作内容。当前活动的工作结果需要进行验证，如果验证通过，则该结果作为下一项活动的输入，继续进行下一项活动，否则返回修改。

　　瀑布模型强调文档的作用，并要求每个阶段都要仔细验证。但是，这种模型的线性过程太理想化，已不再适合现代的软件开发模式，几乎被业界抛弃，其主要问题在于：

　　1） 各个阶段的划分完全固定，阶段之间产生大量的文档，极大地增加了工作量；

　　2） 由于开发模型是线性的，用户只有等到整个过程的末期才能见到开发成果，从而增加了开发的风险；

　　3） 早期的错误可能要等到开发后期的测试阶段才能发现，进而带来严重的后果。

###### 增量模型

与建造大厦相同，软件也是一步一步建造起来的。在增量模型中，软件被作为一系列的增量构件来设计、实现、集成和测试，每一个构件是由多种相互作用的模块所形成的提供特定功能的代码片段构成。

　　增量模型在各个阶段并不交付一个可运行的完整产品，而是交付满足客户需求的一个子集的可运行产品。整个产品被分解成若干个构件，开发人员逐个构件地交付产品，这样做的好处是软件开发可以较好地适应变化，客户可以不断地看到所开发的软件，从而降低开发风险。但是，增量模型也存在以下缺陷：

　　1） 由于各个构件是逐渐并入已有的软件体系结构中的，所以加入构件必须不破坏已构造好的系统部分，这需要软件具备开放式的体系结构。

　　2） 在开发过程中，需求的变化是不可避免的。增量模型的灵活性可以使其适应这种变化的能力大大优于瀑布模型和快速原型模型，但也很容易退化为边做边改模型，从而是[软件过程](https://wiki.mbalib.com/wiki/软件过程)的控制失去整体性。

　　在使用增量模型时，第一个增量往往是实现基本需求的[核心产品](https://wiki.mbalib.com/wiki/核心产品)。核心产品交付用户使用后，经过评价形成下一个增量的开发计划，它包括对核心产品的修改和一些新功能的发布。这个过程在每个增量发布后不断重复，直到产生最终的完善产品。

　　例如，使用增量模型开发字处理软件。可以考虑，第一个增量发布基本的文件管理、编辑和文档生成功能，第二个增量发布更加完善的编辑和文档生成功能，第三个增量实现拼写和文法检查功能，第四个增量完成高级的页面布局功能。

###### 螺旋模型

螺旋模型沿着螺线进行若干次迭代，图中的四个象限代表了以下活动：

　　1） 制定计划：确定软件目标，选定实施方案，弄清项目开发的限制条件；

　　2） 风险分析：分析评估所选方案，考虑如何识别和消除风险；

　　3） 实施工程：实施软件开发和验证；

　　4） 客户评估：评价开发工作，提出修正建议，制定下一步计划。

　　螺旋模型由风险驱动，强调可选方案和约束条件从而支持软件的重用，有助于将[软件质量](https://wiki.mbalib.com/wiki/软件质量)作为特殊目标融入产品开发之中。但是，螺旋模型也有一定的限制条件，具体如下：

　　1） 螺旋模型强调风险分析，但要求许多客户接受和相信这种分析，并做出相关反应是不容易的，因此，这种模型往往适应于内部的大规模软件开发。

　　2） 如果[执行风险](https://wiki.mbalib.com/wiki/执行风险)分析将大大影响项目的利润，那么进行风险分析毫无意义，因此，螺旋模型只适合于大规模软件项目。

　　3） 软件开发人员应该擅长寻找可能的风险，准确地分析风险，否则将会带来更大的风险

　　一个阶段首先是确定该阶段的目标，完成这些目标的选择方案及其约束条件，然后从风险角度分析方案的开发策略，努力排除各种潜在的风险，有时需要通过建造原型来完成。如果某些风险不能排除，该方案立即终止，否则启动下一个开发步骤。最后，评价该阶段的结果，并设计下一个阶段。

###### 敏捷模型



#### 2.***\*《啊哈！算法》\****

##### 问题：讲了什么？

1.排序2.队列、栈、链表3.枚举：1.深度优先搜索2.广度优先算法5.图的遍历

堆(Heap)是[计算机科学](https://baike.baidu.com/item/计算机科学/9132?fromModule=lemma_inlink)中一类特殊的数据结构，是最高效的优先级队列。堆通常是一个可以被看做一棵[完全二叉树](https://baike.baidu.com/item/完全二叉树/7773232?fromModule=lemma_inlink)的数组对象。

##### 问题：有什么排序，原理是什么？

```bash
时间复杂度是总运算次数表达式中受n的变化影响最大的那一项
```

###### 回答：桶排序：

就是假设有10个分数，我们就需要10个桶（已经对应分数排列好的桶），对应一个分数一个桶，每有一个分数就往对应的桶里+1，最后桶里的数字就是对应该分数的个数

桶排序也就是先构建一个1维数组，然后将无序的数字排列依次放进数组中，数字的大小与数组元素在数组中的位置一一对应。相同的数字出现的次数代表1维数组中对应的数组元素的个数，由于数组是有序的，最后将数组中所有元素从前往后或从后往前输出，就能得到有序数列。

桶排序的平均时间复杂度为
$$
O(N+M)
$$
要排序的数据有N个，我们把它们**分在M个桶中**

###### 冒泡排序：

每次比较两个相邻的元素，如果他们的顺序错误就把他们交换过来

冒泡排序也就是从第一个元素开始比较，每次比较两个相邻的元素，如果他们的顺序错误就把他们交换过来，然后重复这一过程。冒泡排序的核心是双重嵌套循环，交换数字的循环在重复过程的循环里面。

冒泡排序的平均时间复杂度为
$$
O(n^2)
$$

###### 快速排序：

将一个数字作为基准数，将大于它的数字放在右边，将小于它的数字放入左边。

快速排序也就是每次排序的时候设置一个基准点，将小于等于基准点的数全部放到基准点的左边，将大于等于基准点的数全部放在基准点的右边，然后循环进行该步骤。它基于二分的思想。

快速排序的平均时间复杂度为
$$
O(nlog_2n)
$$

快速排序所采用的思想是分治的思想。所谓分治，就是指以一个数为基准，将序列中的其他数往它两边“扔”。

###### 插入排序：

也就是先将数据分为两组，有序组和无序组，并且将数据的第一个元素默认为有序组，将无序组的元素一个一个插入到有序组中，插入方式为判断数字在有序组中的位置，最终确定数字的位置。

插入排序的平均时间复杂度为
$$
O(n^2)
$$


###### **选择排序**原理：

  数组分成有序区和无序区，初始时整个数组都是无序区，然后每次从无序区选一个最小的元素直接放到有序区的末尾，最后，直到整个数组变有序区。

选择排序的平均时间复杂度为
$$
O(n^2)
$$


##### 在程序中经常会出现的排序

![](D:\note\相关图片\图片1.png)

###### 问题：队列组成，栈的性质，链表的性质

回答：队列：一个数组两个变量，一进一出。

栈：只需要一个一维数组和一个指向栈顶的top就行，只有一个出口。

链表：用指针存储一个动态内存空间的地址，将两个结点连接起来，进行数据存储

###### 问题：1.深度优先搜索原理

回答：把每一种可能都尝试一遍，当前这一步解决后便进入下一步（访问下一层的位置），当遇到死胡同没有路可走时就返回到初始位置

###### 问题2.广度优先算法原理

回答：某一处将该处所有的可能（向不同的最靠近该处的方向扩展，访问处于同一层的位置）都进行尝试，然后再进行下一步，并且把之前的可能标记为走过，直至终点

通过深度优先和广度优先算法可以计算最短路径

#### 3.体验过一些真正为大众提供便利的软件

###### 问题：哪些软件？怎么提供便利？

哪些软件是比较便利的？该怎么说明它便利在哪一方面？

回答：网易云音乐，一个听歌软件，前端设置简洁,框架清晰，后端强大，数据库强大，每日推荐更会根据你的听歌种类进行准备，

##### 软件是什么？你怎么理解软件的？

软件是一系列按照特定顺序组织的[计算机](https://baike.baidu.com/item/计算机/140338?fromModule=lemma_inlink)数据和[指令](https://baike.baidu.com/item/指令/3225201?fromModule=lemma_inlink)的集合。一般来讲软件被划分为[系统软件](https://baike.baidu.com/item/系统软件/215962?fromModule=lemma_inlink)、[应用软件](https://baike.baidu.com/item/应用软件/216367?fromModule=lemma_inlink)和介于这两者之间的[中间件](https://baike.baidu.com/item/中间件/452240?fromModule=lemma_inlink)。软件程序能够满意地处理信息的数据结构。软件并不只是包括可以在[计算机](https://baike.baidu.com/item/计算机/140338?fromModule=lemma_inlink)上运行的[电脑程序](https://baike.baidu.com/item/电脑程序/265803?fromModule=lemma_inlink)，与这些电脑程序相关的[文档](https://baike.baidu.com/item/文档/1009768?fromModule=lemma_inlink)一般也被认为是软件的一部分。简单的说软件就是程序加文档加数据的集合体。

##### 4.了解了一些基本算法

###### 问题：哪些基本算法？

算法一：快速排序法

快速排序是由东尼·霍尔所发展的一种排序算法。在平均状况下，排序 n 个项目要Ο(n log n)次比较。在最坏状况下则需要Ο(n2)次比较，但这种状况并不常见。事实上，快速排序通常明显比其他Ο(n log n) 算法更快，因为它的内部循环（inner loop）可以在大部分的架构上很有效率地被实现出来。（最快的）

快速排序也就是先设置一个基准量，然后

算法四：二分查找算法               

  二分查找算法是一种在有序数组中查找某一特定元素的搜索算法。搜素过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜素过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。这种搜索算法每一次比较都使搜索范围缩小一半。折半搜索每次把搜索区域减少一半，时间复杂度为Ο(logn) 

##### 5.生活中一些方面急需更智能的软件来优化服务

###### 问题：哪些方面？需要怎么样的软件？软件怎么样更智能？怎么优化服务？

成本更低，服务更好的实用性软件，对软件的架构进行优化，对软件的各个模块进行优化

###### 问题：你认为该怎么样才能成本更低，服务更好？

1.减少开发周期时间节省开发成本费。

2.高效率的做好商品整理。

3.确保开发出的商品高品质的合乎用户需求。

##### 6.本学科基本信息有了一个大致了解

###### 问题：了解了什么？软件工程是干什么的？

采用工程的概念、原理、技术和方法来开发和维护软件，把经过时间考验而验证正确的管理技术和当前能够得到的最好的技术方法结合起来，以经济的开发处高质量的软件并有效地维护它。

##### 7.我的个人目标与学科培养目标高度契合

###### 问题：学科培养目标是什么？你的个人目标是什么？为什么高度契合？

培养具有良好软件设计能力、国际交流能力、管理与沟通能力和职业发展能力的复合型、应用型高层次并具有 国际竞争力的未来软件工程领军人才，使学生毕业后能够从事软件系统的分析设计与开发、项目管理以及软件系统 的运行维护等方面的工作。

个人目标：在大学打好基础，主动学习，拓宽视野，并参加一些计算机比赛，实习积累经验，并争取出国交流的机会。毕业后保研本校或考研。我目标在移动开发和前端领域工作，并致力于***\*个性化的SaaS领域\****，

##### 8.我对***\*实践方向\****有强烈兴趣

###### 问题：有实践过吗？实践了什么项目？

回答：勤创开发项目工作中，参加了编写一个摄影网站的任务，未来我也会参与到更多类似的项目与工作。

##### 9.我对新鲜事物与信息领域高新技术有很强的好奇心，我会思考新技术如何为我们所用

###### 问题：你知道什么新鲜事物与信息领域高新技术？你认为新技术该如何为我们所用？

比如敏捷软件开发方法，1.较之于过程与工具，应更加重视人和交互的价值2.较之于面面俱到的文档，应该更加重视可运行软件的价值3.较之于合同谈判，应更加重视客户合作的价值，较之于遵循计划，应更加重视响应用户需求变化的价值。从小工具开始，当小工具无法满足要求时再考虑选择和使用功能更加强大的工具。

敏捷软件开发的特点：小（软件迭代周期小）、简（解决的问题简单，所使用的工具简单）、快（快速响应变化，快速更迭）、变、体

比如novelai，一个新的人工智能绘画网站，通过人工智能的不断学习可以省去画师极大的时间成本与工作量,在保证不侵损他人的利益的前提下,让社会中的每一个人都能用上新技术.

##### 10.我正在学习心理学相关课程，在未来的学习研究中心理科学与软件理论交叉，定能碰撞出别样的火花

###### 问题：心理科学与软件理论两者如何交联？

软件在本质上是主体思维的“语言”表 达[2]，软件缺陷不同于硬件缺陷，它与人为因素密切相关。软 件心理 学正是 综合软件 工程与心理 学理论 、研究 软件开 发本 质的一门交叉学科 。

软件心理学在人机交互中主要应用于用户建模及可用性 的设计与验证，关注用户描述，对用户的感知、认知和动作进 行建模，并构建感知一认知一动作 的集成建模。该方面的应用 旨在了解和支持人与计算机的交互，使设计的软件或系统的 可用性更高 。

##### 11.我目标在移动开发领域工作，并致力于***\*个性化的SaaS领域\****

###### 问题：移动开发和前端领域是干什么的？Saas是什么？你认为该怎么样将Saas个性化？

移动前端开发属于前端开发的范围，目前前端发展的趋势就是大前端，可以说是包罗万象，当然也就包含PC端和移动端领域

大前端就是所有前端的统称，比如Android、iOS、web、Watch等，最接近用户的那一层也就是UI层，然后将其统一起来，就是大前端

移动开发领域有：云与移动开发

**IaaS**：基础设施即服务，
Infrastructure-as-a-service

基础设施即服务。有了laaS，企业在开发APP时，只需在公有云平台上注册一个账号，花点钱，配置各种云服务器，各种大小的存储，各种带宽的网络，都配齐，不用操心诸如机房选址、设备采购、实体服务器、存储、网络等问题，只要一个账号，便解决了。

**PaaS**：平台即服务，Platform-as-a-service

PaaS是在IaaS的基础之上，解决了操作系统、数据库、运行时环境runtime、中间件、各种框架的搭建操作问题，有了PaaS，程序员只需要专心的开发自己的APP就行了

**SaaS**：软件即服务，Software-as-a-service

**IaaS，提供最底层服务**。最接近服务器硬件资源，这样用户可以以最大的自由度接入网络本身；

**PaaS，提供更高一层服务**。整体服务向用户隐藏了底层的网络，存储，操作系统等等技术问题，也就是说底层服务对用户是透明的，而向用户开放的是软件本身的开发和运行环境；

**SaaS，提供最上层服务**。大部分用户会用简单客户端的方式调用该层级的服务。用户可以根据自己的需求，通过网络向供应商订制商业模型，一些比较简单的例子是Google的文档，表格等等。

Saas就是软件即服务。我们可以通过人工智能的加入，使原来一个完整的软件可以自动产生不同的模块，在同一个软件框架下能够运行不同的模块组合，实现Saas个性化。

对于企业来说，SaaS软件带来更多的选择自由，在产品功能、付费模式、部署方式上，不用受限于传统软件的束缚，可以根据自身情况进行个性化的选择。同时，由于订阅许可的付费方式，让企业初期的成本变得更低。

比如Typora,WPS Office,钉钉都是Saas

##### 12.国家“大数据背景下智慧城市的建设”方向奉献自己的一份力

###### 问题：你认为你选择软件工程该如何在这个方面为国家效力？

制作软件是市民用得更加方便，利用异步减少浪费的资源。

### 自我介绍部分

##### 1.冯诺依曼用人列计算机制作的软件来推算三体的运动规律所打动

###### 问题：怎么制作的？

用手持黑白棋的三千万士兵来模拟0和1的二进制运算法则，构建计算机最最基本的计算单元与、或、非门，以及与非门、或非门、异或门、同或门和三态门；同时，组建一千万个这样的门部件，再将这些部件组合成一个系统，构成了计算机系统。

##### 2.勤创的二面以及例会中锻炼了自己的自学能力以及信息检索能力

###### 问题：你的信息检索能力怎么体现的？

一、掌握一点搜索引擎高级语法知识；

比如intitle:  (需要包含关键字)

filetype:  (表示文件是什么格式)

and(表示要包含前后的关键词)

快捷键Ctrl+F ：页内搜索(对某些字、词进行页内搜索，也就相当于把关键词突出显示)

二、了解一些有效的信息资源站点；

1、 中国知网

2、**YOUMEEK**：i.youmeek.com

3、AA：http://lackar.com/aa/

4.[Stock.us](https://link.zhihu.com/?target=https%3A//stock.us/cn/report/strategy)（看研报的网站）

5.**果壳任意门**：gate.guokr.com

三、构建个人的信息收集网络，需要从静、动两个方面入手。

从静的方面入手，则主要是构建自己的信息搜索体系。（也就是对自己搜集的零散碎片信息进行分类统合）

而从动的方面入手，主要是找到合适的圈子或者专家。

##### 3.在与同学和学长们的交流中锻炼了自己的沟通技巧和逻辑思考能力

###### 问题：你们沟通交流了什么？怎么锻炼的？

这个会问吗？

## 其他专业等方面的问题

### ***\**\*\*\*软件危机是什么？\*\*\*\*\****

***\**\*\*\*软件危机\*\*\*\*\****是指软件在***\**\*\*\*开发\*\*\*\*\*******\**\*\*\*和\*\*\*\*\*******\**\*\*\*维护\*\*\*\*\****的过程中出现的一系列严重的问题。
两个问题：

***\**\*\*\*一是如何开发软件，如何满足对软件日益增长的需求。\*\*\*\*\****

***\**\*\*\*二是如何维护数量不限已经膨胀的已有软件\*\*\*\*\****。

#### ***\**\*\*\*软件危机的表现\*\*\*\*\****

***\**\*软件的开发成本和进度估计不准确。\*\**\*
\**\*\*用户对已经开发出来的软件不满意。\*\**\*
\**\*\*软件没有合适的文档资料。\*\**\*
\**\*\*软件的成本在公司的总成本中逐年上升。\*\**\*
\**\*\*软件产品的质量常常不可靠。\*\**\*
\**\*\*软件常常是不可维护的。\*\**\***

#### ***\**\*\*\*软件危机出现的原因\*\*\*\*\****

***\**\*\*\*一是指软件生产自身存在的复杂性。\*\*\*\*\****
***\**\*\*\*二是指与软件开发过程中使用的方法和技术有关\*\*\*\*\****。

### 软件开发流程

1.问题定义：也就是弄清用户需要用该软件解决什么问题，提出"系统目标和范围的说明“

2.可行性分析：把待开发系统的目标以明确的语言描述出来，并从经济、技术、法律等多个方面进行可行性分析。

3.需求分析：弄清用户对软件系统的全部需求。

开发阶段：设计软件的功能和实现的算法和方法、软件的总体结构设计和[模块设计](https://baike.baidu.com/item/模块设计/4815800?fromModule=lemma_inlink)、编码和调试、程序联调和测试以及[编写](https://baike.baidu.com/item/编写/1517598?fromModule=lemma_inlink)、提交程序，包括以下流程

4.软件设计（包括总体设计（总体设计、初步设计、逻辑设计、高层设计）和详细设计（模块设计、物理设计、低层设计））

总体设计：概括地说，怎样实现目标系统？

确定解决问题的方案及目标系统中应该包含的程序。

设计程序的体系结构，确定程序由哪些模块组成以及模块间的关系。

详细设计：把解决办法具体化，详细地设计每个模块，确定实现模块功能所需要的算法和数据结构。

5.程序编码和单元测试

把详细设计的结果翻译成用选定的语言书写的程序，并且仔细测试编写出的每一个模块。

6.软件测试

通过各种类型的测试及相应的调试使软件达到预定的要求。最基本的测试是集成测试和验收测试。

集成测试（组装测试）：根据设计的软件结构，把经过单元测试检验的模块按某种选定的策略装配起来，在装配过程中对程序进行必要的测试。【前后端联调】

验收测试（确认测试）：按照规格说明书的规定，由用户对目标系统进行验收。【UAT测试】

7.运行与维护：

通过各种必要的维护活动使系统持久地满足用户的需要，包括四类维护活动：

改正性维护：诊断和改正软件错误（由于开发测试的不彻底、不完全）

适应性维护：修改软件以适应环境的变化

完善性维护：根据用户要求改进或扩充软件使它更完善（使用过程中提出的一些建设性意见）

预防性维护：修改软件为将来的维护活动预先做准备（改善软件系统的可维护性和可靠性）

#### 软件开发生命周期（SDLC）的六个期：

1.问题的界定和方案。此轮是软件开发人员和需求方之间的探讨，以此确认软件开发目标和可行性。

2.需求分析。在确定软件开发可行的情况下，将对软件需要实现的每个功能进行详细分析。需求分析阶段是非常重要的阶段。这个阶段做得很好，将为整个软件开发项目的成功奠定良好的基础。

3.软件设计。在此阶段，将根据需求分析的结果来设计整个软件系统，例如系统框架设计，数据库设计等。软件设计一般分为总体设计和详细设计。

4.程序编码。这个阶段是将软件设计的结果转换成计算机可运行的程序代码。在程序编码中，有必要制定统一的，符合标准的书写规范。

5.软件测试软件设计完成后，必须进行严格的测试，以找出软件设计过程中的问题并加以纠正。整个测试过程分为三个阶段：单元测试，组装测试和系统测试。测试方法主要包括白盒测试和黑盒测试。在测试过程中，需要建立详细测试计划，并严格按照测试计划进行测试，以减少测试的随机性。

6.操作和维护。软件维护是软件生命周期中最长的时间。软件开发完成并投入使用后，由于各种原因，该软件将无法继续适应用户的需求。为了延长软件寿命，必须维护软件。软件维护包括纠错维护和改进的维护。

### **你在查看代码时会注意什么**

我会密切注意功能，可读性以及代码是简单还是混乱。还要注意代码中可能存在的缺陷，处理哪些必须重写或删除的代码。关注代码中可能缺失,遗漏的点,避免犯低级错误.

### 和计算机科学与技术专业有什么区别

平行的本科专业
软件工程是和计算机科学与技术平行的一个本科专业。

培养的目标不同
软件工程与计算机科学与技术的培养目标不同。
计算机科学与技术，可以偏向科学理论方向，也可以偏向技术应用方向，对于科学理论方向基本都是高精尖的学校专业人才，大部分人还是会偏向于技术应用方向，一技在手，天下我有。两个专业开设的基础课程是比较相似的，专业课程则因各学校的培养目标的差异而有所不同，计算机科学与技术注重科学理论方向的学习、专业技术的研发，基础性相对更强；软件工程注重应用实现，其在产品研发管理方向专业性更强。

受众群体不同
在受众群体上，计算机科学与技术理论上面向的是计算机软件行业技术人员，为行业提供技术知识理论或底层系统，软件工程面向的是终端产品用户。

宏观与微观
对于产品来说，计算机科学与技术（应用方向）偏向微观，专注于点，讲究深度；软件工程偏向宏观，专注过程，讲究广度；
两个专业的课程大部分差异不大，只是在方向上有大一样，计算机科学与技术更偏向技术研究，软件工程更偏向于产品实现，对于技术知识来说两个专业都可以互相转换，没有必要深究，但最终都是为了产品，软件工程虽然自身可以在技术方面下功夫，但更注重产品研发管理，计算机科学与技术更注重理论研究及技术点的研发。

## 如何理解自然对数e

e是增长的极限，微积分极限

### 怎样调试程序

#### 程序开发中的错误

##### 1.编译期错误（语法错误）

比如格式不符合规定，不存在的标号，不恰当的嵌套，对象说明与使用不一致，不正确的分隔符等等

##### 2.连接错误

比如函数名书写错误，缺少包含文件，文件的路径错误等

##### 3.运行期错误

比如在计算过程中遇到除数为0的错误，求一个负数的平方根等

（程序设计者可以在程序中编入一些有自己来检查这类错误的程序段，适合自己的处理要求）

##### 4.逻辑性错误

比如把log写成log10，把x+y写成x-y等（此类错误编程系统无法查出）

##### 5.警告性错误

比如源程序中发现了一个定义过但从未使用过的变量



### 调试方法

#### 1.跟踪调试

一种有效的调试程序的方法，是一种通过人工控制程序执行过程，比对主观和客观的程序执行过程和中间结果以发现和改正错误的调试程序的方法，本质上就是让程序一行一行的执行或者按照我们的要求执行若干行。

#### 2.设置断点

程序执行到当前这一行，停止执行，这样的位置就叫做断点

### 黑盒，白盒测试分别指什么

白盒测试也叫做[alpha测试](https://wenwen.sogou.com/s/?w=alpha测试&ch=ww.xqy.chain)，是指程序设计员为了验证程序的逻辑过程而进行的测试，因知道内部原理而得名。[黑盒测试](https://wenwen.sogou.com/s/?w=黑盒测试&ch=ww.xqy.chain)也[beta测试](https://wenwen.sogou.com/s/?w=beta测试&ch=ww.xqy.chain)，是由客户（使用者）进行的测试，目的在于检验程序的功能，因不知道其内部结构而得名。

### ***\*你是否了解过软件测试中的α测试和β测试，请简述它们的区别。\****

#### 1.测试时间不同

Beta测试是软件产品完成了功能测试和系统测试之后，在产品发布之前所进行的软件测试活动，它是技术测试的最后一个阶段。

alpha测试简称“α测试”，可以从软件产品编码结束之时开始，或在模块(子系统)测试完成之后开始，也可以在确认测试过程中产品达到一定的稳定和可靠程度之后再开始。（

#### 2.测试的目的不同

α测试的目的是评价软件产品的FLURPS（即功能、局域化、可用性、可靠性、性能和支持）。尤其注重产品的界面和特色。α测试即为非正式验收测试。

Beta测试是一种验收测试，通过了验收测试，产品就会进入发布阶段。

#### 3测试人员及场所不同

α测试是由一个用户在开发环境下进行的测试，也可以是公司内部的用户在模拟实际操作环境下进行的受控测试，α测试不能由程序员或测试员完成。α测试发现的错误，可以在测试现场立刻反馈给开发人员，由开发人员及时分析和处理。

Beta测试由软件的最终用户们在一个或多个客户场所进行。开发者通常不在Beta测试的现场，因Beta测试是软件在开发者不能控制的环境中的“真实”应用。

### 操作系统是什么，它的原理大概是什么

操作系统（Operating System，简称OS）是管理和控制[计算机硬件](https://baike.sogou.com/lemma/ShowInnerLink.htm?lemmaId=507169&ss_c=ssc.citiao.link)与软件资源的[计算机程序](https://baike.sogou.com/lemma/ShowInnerLink.htm?lemmaId=157144&ss_c=ssc.citiao.link)，用户和计算机的接口，同时也是计算机硬件和其他软件的接口。

其能[管理计算机](https://baike.sogou.com/lemma/ShowInnerLink.htm?lemmaId=550633&ss_c=ssc.citiao.link)系统的硬件、软件及数据资源，控制程序运行，改善人机界面，为其它应用软件提供支持，并使计算机系统所有资源最大限度地发挥作用。此外其还提供了各种形式的用户界面，使用户有一个好的工作环境，为其它软件的开发提供必要的服务和相应的接口。

操作系统原理其实就是用各种的数据构建成一个庞大的数据库，任何程序的应用都需要通过这个操作系统来完成，这是最为基础的。

### 介绍一下你所了解的计算机术语

access，获取，存取

Active Directory，活动目录

Add Parameter，添加参数

agent，代理

agent-based interface，代理人界面

Agile，敏捷方法论

agile practice，敏捷实践



### 描述一下冒泡排序

冒泡排序（Bubble Sort），是一种计算机科学领域的较简单基础的排序算法。其基本思路是，对于一组要排序的元素列，依次比较相邻的两个数，将比较小的数放在前面，比较大的数放在后面，如此继续，直到比较到最后的两个数，将小数放在前面，大数放在后面，重复步骤，直至全部排序完成。

这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“冒泡排序”。

#### **时间复杂度**

若文件的初始状态是正序的，一趟扫描即可完成排序。所需的关键字比较次数![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps1.png)和记录移动次数![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps2.png)均达到最小值：![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps3.png)，![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps4.png)。

所以，冒泡排序最好的时间复杂度为![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps5.png)。

若初始文件是反序的，需要进行![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps6.png)趟排序。每趟排序要进行![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps7.png)次关键字的比较(1≤i≤n-1)，且每次比较都必须移动记录三次来达到交换记录位置。在这种情况下，比较和移动次数均达到最大值：

![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps8.png) 

![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps9.png) 

冒泡排序的最坏时间复杂度为![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps10.png)。

综上，因此冒泡排序总的平均时间复杂度为![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps11.png)。

#### 算法稳定性

因为相同元素的前后顺序并没有改变，冒泡排序是一种稳定排序算法。

#### 冒泡排序如何改进

冒泡排序改进1：在某次遍历中如果没有数据交换，说明整个数组已经有序。因此通过设置标志位来记录此次遍历有无数据交换就可以判断是否要继续循环。

 冒泡排序改进2：记录某次遍历时最后发生数据交换的位置，这个位置之后的数据显然已经有序了。因此通过记录最后发生数据交换的位置就可以确定下次循环的范围了。

### 介绍一下二分搜索算法(分析一下复杂度)

二分搜索算法的时间复杂度为O(logn)以2为底



### **希尔排序**原理

先将整个待排元素序列分割成若干个子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序。由于希尔排序是对相隔若干距离的数据进行直接插入排序，因此可以形象的称希尔排序为“跳着插”

### **快速排序**原理

 “挖坑填数+分治法”，首先令i =L; j = R; 将a[i]挖出形成第一个坑，称a[i]为基准数。然后j--由后向前找比基准数小的数，找到后挖出此数填入前一个坑a[i]中，再i++由前向后找比基准数大的数，找到后也挖出此数填到前一个坑a[j]中。重复进行这种“挖坑填数”直到i==j。再将基准数填入a[i]中，这样i之前的数都比基准数小，i之后的数都比基准数大。因此将数组分成二部分再分别重复上述步骤就完成了排序。



### C语言程序从编译到可执行程序的运行中间的一步

编辑，编译，连接，执行

1.编辑：编写代码，制作C语言的源文件。

2、编译：是由编译程序将C语言源文件转换成二进制中间文件，对文件内部的语法语义做处理，如果编译出错，无法进行后续动作。

3、链接：将编译中生成的中间文件组合成二进制可执行文件，这一步会对文件之间的关联做检查，如果出错，将不会生成可执行文件，也就无法执行。

4、执行：运行可执行文件，这一步道是编写代码的最终目的

### 讲一下你所理解的好的编程习惯

##### **1.不受控制的自动保存** 

 这个习惯已经伴随着我多年了。即使如今许多 IDE 甚至不需要用户（主动）保存文件，但我任然乐此不疲地按着“Ctrl + S”这个组合键。如果没记错的话，我每次停止打字时都会无所事事，于是会不受控制地做着这样的举动。

##### **2.****定期的进站（休息/恢复）**

有些开发人员喜欢将自己“处在状态”比喻成“涅槃重生”或者是到达了“瓦尔哈拉殿堂”。在我看来，这更像是一种“暴走模式”。显而易见，这是生产效率非常惊人的一段时间，但之后你应该休息片刻来调整恢复（你体内的激素水平）。就像 F1 方程式赛车一样，短时间的爆发冲刺将直接影响最终成绩，但是更重要的是要确保“**定期的进站（休息/恢复）**”。长时间亢奋反而会让大脑麻木，从而导致更容易陷入困境。

##### **3.确保隔绝所有干扰源** 

当我正在着手于非常重要的事项时，我会直接关闭手机，避免一切社交应用或者媒体的打扰。当然如果你有小孩子，那把他们锁在地下室里可能并不是一个很好的解决方案 :)。

##### **4.着手工作前先想清楚预期结果** 

可视化可度量是至关重要的。它有助于我明确今天的目标清单，并且在一天结束时能减少自己“碌碌无为”而产生的沮丧和失望。所以对于任何时候你在做的事情，都先明确你预期要获得的收益。这听起来十分浅显，但实际上我们经常会遗漏这一点。

##### **5.保持定期训练**

对我来说，另一个好习惯是“**保持定期训练**”。比如，坚持去健身就是一个非常好的习惯。我非常喜欢时不时得做一些编程练习，这可以让我时刻保持自己的锯子锋利无比。请记住，坚持这个习惯，虽然它现在不会给你带来报酬，但它一定会在未来给你巨大的收益。

##### **6.“****测试先行****”** 

这与前面提到的一点类似，先来组织并构建测试用例可以帮助我在开始之前就看到我的目的地。同时，它也能有助于设计和文档化这两个过程。但实际情况来看，很少有开发人员认同并实践这个观点。

##### **7.避免过度的追求完美的编程

之前我每次着手编程时，我总是第一天就力求完美，设计和实现上都尝试覆盖所有可能的特殊情况（edge cases）。随着时间的推移，我意识到这样常常会导致过度复杂的设计和代码实现，同时消耗更多的时间。劳逸结合，注重细节，注意区分

### 扫雷游戏的原理

英国一位数学家用扫雷游戏中的逻辑规律构建了一系列电子元件，用电子电路模拟雷区。他试图将一个的给定的雷区图案交由计算机来判断是否可解。如果随着格子数量的增加，电脑的计算量增长不是很快，就是P问题，如果计算量增加的很快，就是NP问题。计算机判断雷区是否可解，需要这类问题属于P问题才可以。对于几种基本的电路元件（AND、OR、NOT），如果将很多个这样的元件组合起来，相互连接，就会产生很多个输入、输出口。判断最后哪些输出结果可以产生，哪些不可以产生的这类问题，被称为SAT问题，它属于一个经典的NP完全问题。而英国数学家的这个问题在一些时候等同于一个复杂电子电路的SAT问题，也就是NP完全问题。由此看来，面对一个上千上万个格子的巨型雷区，不要说去完成所有扫雷任务，就仅仅判断它是不是可解的，都可能会是计算机也承受不了的的大难题。

埋雷，数雷，现雷，对零的处理

扫雷游戏分为几个步骤

##### 第一步，使用[二维数组](https://so.csdn.net/so/search?q=二维数组&spm=1001.2101.3001.7020)表示地图；

##### 第二步，随机生成几个地雷；

##### 第三步，点击方格的反应，计算每个非雷区方格点开后的数字；

计算非雷区方格点开后的数字就把这个方格在二维数组中周围八个方向的方格是否是地雷都检查一遍，一定要注意不要越出数组边界。

这个数字可以在游戏初始化时全都计算好，也可以在玩家点击的时候再计算。

点击非雷区方格，显示数字，这个方格标记为“已点过”。

如果想插旗子，也是给这个方格一个标记。这两个标记都是布尔型的。

##### 第四步，当方格数字为0的情况；

当方格数字为0时，我想这个应该是这个游戏最难的地方，这里要用到递归调用，就是让程序自动“点击”这个数字为0方格周围的八个方格，然后再看结果，如果不是0，就停止，如果是0，依然递归调用，直到没有0为止，或者直到点遍所有方格为止，再次提醒一下，一定要注意不要越出数组边界。

##### 第五步，当方格为地雷的情况。

宣布玩家死亡就可以了。

### 浙大体艺如何实现打卡

GPS

### 计算机领域一位令人尊敬的人物(著名人物)

**艾伦·麦席森·图灵**

艾伦·麦席森·图灵（Alan Mathison Turing，1912年6月23日－1954年6月7日），英国数学家、逻辑学家，被称为计算机科学之父，人工智能之父。

   图灵在科学、特别在数理逻辑和计算机科学方面，取得了举世瞩目的成就，他的一些科学成果，构成了现代计算机技术的基础。图灵构建了用于破译德国Enigma代码的Colossus计算机、提出了“计算能力”的概念、构思出了名为图灵机的计算机抽象模型、在人工智能的领域提出了一种用来测试机器智能的方法——图灵测试法。

​    图灵机模型为现代计算机的逻辑工作方式奠定了基础。美国计算机协会（ACM）于1966年设立了著名的图灵奖（计算机界的诺贝尔奖）以纪念这位伟大的先驱。

**2.冯·诺依曼**

 冯·诺依曼（John von Neumann，1903~1957），原籍匈牙利，布达佩斯大学数学博士。20世纪最重要的数学家之一，在现代计算机、博弈论、核武器和生化武器等领域内的科学全才之一，被后人称为“计算机之父”和“博弈论之父。

  1944年，诺伊曼参加原子弹的研制工作，该工作涉及到极为困难的计算。被计算所困扰的诺伊曼在一次极为偶然的机会中知道了ENIAC计算机的研制计划，从此他投身到计算机研制这一宏伟的事业中，建立了一生中最大的丰功伟绩。在冯·诺依曼的影响下，整个研制工作取得了突破性的进展。冯·诺依曼及其团队成员提出了新的改进方案：一是新机器由五个部分组成，包括：运算器、控制器、存储器、输入和输出设备；二是用二进制代替十进制，进一步提高电子元件的运算速度；三是存储程序(Stored Program)，即把程序放在计算机内部的存储器中，换言之，把能进行数据处理的程序放在数据处理系统内部，程序和该程序处理的数据用同样的方式储存，即把程序本身当作数据来对待。应用此概念的计算机被统称为冯•诺伊曼体系的计算机。

**3.查尔斯·巴贝奇**

查尔斯·巴贝奇（Charles Babbage，1792—1871），英国发明家、计算机先驱。提到巴贝奇，首先想到的可能就是巴贝奇差分机。

   巴贝奇计算机先驱的称呼主要是为了肯定他在计算机方面的贡献。巴贝奇于1812年的时候用机械来计算数学，之后制造了一台小型的计算机。这台计算机能够进行八位数的数学运算。在1823年政府的支持下想制造出一台容量为二十位数的计算机。由于当时制造计算机需要很高的机械技术，巴贝奇于是又开始从事机械方面的研究。

​    经过数年的努力之后，巴贝奇于1834年发明了分析机的原理，这个分析机的原理就是计算机的前身。在分析机的制作过程中，巴贝奇设想根据储存数据的穿孔卡上的指令进行任何数学运算的可能性，这一设想非常符合现在计算机的各种特性。但是由于政府拒绝支持计算机的制作，导致计算器未能完成，但是其理念对后世影响深远。

### 你见过的最复杂的程序是什么？大概功能/原理是什么？

进行快速排序的程序

### 知道GitHub，对此类开源社区怎么看待？

这是一个非常好的社区，满足了学习，我觉得GitHub最大的价值在于，它把全世界最优秀的人拉到了一起，让你触手可及，就好像坐在你隔壁的团队大哥一样。没有GitHub的时候，你能够想象有一天你可以通过点几下鼠标，就和这个星球上最顶尖的高手沟通么？

并且这个社区没有任何门槛。

Github就是一个平台而已，不是说用了Github就一定能提高代码能力，但是起码能够给用户一个接触大佬的机会（StackOverflow可以得到大佬的解答），在这里是真的可以见到一些大佬的代码，甚至参与到大佬代码的开发中。（大佬不仅指某个人，也指某些比较厉害的公司、团队）。

### 知道数据结构吗？介绍一下你知道/了解的数据结构

数据结构（data structure）是计算机存储、组织数据的方式，指相互之间存在一种或多种特定关系的[数据元素](https://baike.sogou.com/lemma/ShowInnerLink.htm?lemmaId=54652569&ss_c=ssc.citiao.link)的集合，往往同高效的检索算法和索引技术有关。大多数数据结构都由数列、记录、可辨识联合、引用等基本类型构成。通常情况下，精心选择的数据结构可以带来更高的运行或者存储效率。

数据结构意味着接口或封装，一个数据结构可被视为两个函数之间的接口，或者是由数据类型联合组成的存储内容的访问方法封装。

数据结构是计算机存储、组织数据的方式；通常情况下，精心选择的数据结构可以带来更高的运行或者存储效率。数据结构的优良将直接影响着我们程序的性能；常用的数据结构有：数组（Array）、栈（Stack）、队列（Queue）、链表（Linked List）、树（Tree）、图（Graph）、堆（Heap）、散列表（Hash）等；


###  你所学习的线性代数，微积分在计算机领域有哪些运用

线性代数在机器学习中比较低阶的应用是矩阵运算，比如softmax分类器 ![img](file:///C:\Users\DELL\AppData\Local\Temp\ksohtml26368\wps12.jpg)，在这里矩阵形式使得书写、计算更方便，也能帮助理解模型(将矩阵看作是一种变换)；高阶一点的应用在无监督学习中，可以参考奇异值分解(SVD)等矩阵分解方法在特征降维、嵌入方面的应用，在这些应用场景中，主要利用的是矩阵的特征值等性质；还有矩阵的正定性，在凸函数的证明等很多方面也可以用到。另外，线性代数也是数值分析等优化课程的必要先修课。私以为机器学习是一门数学与计算机的交叉学科，因此线性代数在里面发挥的作用很大

### 讲一讲数学在计算机领域的应用

#### **从计算机系课程的角度：**

微积分：计算机建模

**线性代数**(很重要)：很多问题最终都能化为求解线性方程组问题；线性代数知识还常在机器学习或数据挖掘中被用来降低数据的维度

概率论,数理统计,随机过程：人工智能领域，很多机器学习算法(统计学习算法？)基于统计模型——例如Bayes 统计

数值分析：在计算机上应用数学知识；用数值方法解一些无法求出解析解的方程

#### **从专业需求的角度**

信息安全：数论、代数(代数几何)

算法：具体数学，运筹学，图论，组合数学

图形处理：解析几何，射影几何，微分几何，黎曼几何，代数几何，拓扑学，样条理论，曲线与曲面的表示(？)，偏微分方程，反问题(？)，傅里叶分析，小波分析

###  图灵对计算机有哪些贡献？

#### 1.提出“图灵测试”概念 

“图灵测试”指测试者zhi与被测试者（一个人和一台机器）隔开的dao情况下，通过一些装置（如键盘）向被测试者随意提问。

进行多次测试后，如果有超过30%的测试者不能确定出被测试者是人还是机器，那么这台机器就通过了测试，并被认为具有人类智能。

图灵测试一词来源于计算机科学和密码学的先驱艾伦·麦席森·图灵写于1950年的一篇论文《计算机器与智能》，其中30%是图灵对2000年时的机器思考能力的一个预测，目前我们已远远落后于这个预测。

图灵预言，在20世纪末，一定会有电脑通过“图灵测试”。2014年6月7日在英国皇家学会举行的“2014图灵测试”大会上，举办方英国雷丁大学发布新闻稿。

宣称俄罗斯人弗拉基米尔·维西罗夫（Vladimir Veselov）创立的人工智能软件尤金·古斯特曼（Eugene Goostman）通过了图灵测试。

虽然“尤金”软件还远不能“思考”，但也是人工智能乃至于计算机史上的一个标志性事件。

#### 2、图灵机

图灵机是由图灵在1936年提出的，它是一种精确的通用计算机模型，能模拟实际计算机的所有计算行为。

所谓的图灵机就是指一个抽象的机器，它有一条无限长的纸带，纸带分成了一个一个的小方格，每个方格有不同的颜色。有一个机器头在纸带上移来移去。

机器头有一组内部状态，还有一些固定的程序。在每个时刻，机器头都要从当前纸带上读入一个方格信息，然后结合自己的内部状态查找程序表，根据程序输出信息到纸带方格上，并转换自己的内部状态，然后进行移动。

#### 3、人工智能

1949年，图灵成为曼切斯特大学（University of Manchester ）计算实验室的副院长，致力研发运行Manchester Mark 1型号储存程序式计算机所需的软件。

1956年图灵的这篇文章以“机器能够思维吗？”为题重新发表，此时，人工智能也进入了实践研制阶段。图灵的机器智能思想无疑是人工智能的直接起源之一。

而且随着人工智能领域的深入研究，人们越来越认识到图灵思想的深刻性：它们如今仍然是人工智能的主要思想之一。

#### 4、树立生物学

从1952年直到去世，图灵一直在数理生物学方面做研究。他在1952年发表了一篇论文《形态发生的化学基础》(The Chemical Basis of Morphogenesis)。

他主要的兴趣是斐波那契叶序列，存在于植物结构的斐波那契数。他应用了反应-扩散公式，如今已经成为图案形成范畴的核心。他后期的论文都没有发表，一直等到1992年《艾伦·图灵选集》出版，这些文章才见天日。

#### 5、判定问题

1937年，图灵用他的方法解决了著名的希尔伯特判定问题：狭谓词演算(亦称一阶逻辑)公式的可满足性的判定问题。

他用一阶逻辑中的公式对图灵机进行编码，再由图灵机停机问题的不可判定性推出一阶逻辑的不可判定性。他在此处创用的“编码法”成为后来人们证明一阶逻辑的公式类的不可判定性的主要方法之一。

在判定问题上，图灵的另一成果是1939年提出的带有外部信息源的图灵机概念，并由此导出“图灵可归约”及相对递归的概念。

运用归约和相对递归的概念，可对不可判定性与非递归性的程度加以比较。在此基础上，E．波斯特(Post)提出了不可解度这一重要概念，这方面的工作后来有重大的进展。

[图灵](https://wenwen.sogou.com/s/?w=图灵&ch=ww.xqy.chain)机[图灵机](https://wenwen.sogou.com/s/?w=图灵机&ch=ww.xqy.chain)是由图灵在1936年提出的，它是一种精确的通用计算机模型，能模拟实际计算机的所有计算行为。

所谓的图灵机就是指一个抽象的机器，它有一条无限长的纸带，纸带分成了一个一个的小方格，每个方格有不同的颜色。有一个机器头在纸带上移来移去。

机器头有一组内部状态，还有一些固定的程序。在每个时刻，机器头都要从当前纸带上读入一个方格信息，然后结合自己的内部状态查找程序表，根据程序输出信息到纸带方格上，并转换自己的内部状态，然后进行移动。[图灵测试](https://wenwen.sogou.com/s/?w=图灵测试&ch=ww.xqy.chain)

1950年他发表论文《计算机器与智能》（ Computing Machinery and Intelligence），为后来的人工智能科学提供了开创性的构思。提出著名的“图灵测试”，指出如果第三者无法辨别人类与人工[智能机](https://wenwen.sogou.com/s/?w=智能机&ch=ww.xqy.chain)器反应的差别， 则可以论断该机器具备人工智能。

### Wifi的全称是什么 

wireless fidelity 无线网络通信技术

### 果连续一天写代码都没有成功，你会怎么办？

休息，立刻睡觉或者锻炼听音乐，找一些方式让大脑放松。可以等头脑清醒时再次编程，检查程序不要让低级失误阻拦自己，换一种思维方式，不要局限于一种固态化思维模式

### 用任意数值的砝码来称出1~100g不同的物体，怎么称？为什么是最少？

如果问称量1—100g之间所有的整数克数需要多少砝码,且砝码与重物分别放在不同的天平秤盘上则如同楼上所说，需要1、2、4、8、16、32、64克共7个砝码。实际上这七个砝码可以称出1—127g之间所有的整数克数。
比如所称重物是43克，就在砝码秤盘里放上1、2、8、32克四个砝码。
但是，假如两个秤盘都可以放砝码，则只需要1、3、9、27、81克共5个砝码就行了。这五个砝码可以称出1—121g之间所有的整数克数。

### 计算机是如何计算平方根

#### 二分法

实际上，对于一个数x，其解必定在（0,x）之间，那么将x/2作为猜测值，若大了，说明解在区间（0，x/2）之间，若小了，说明解在区间（x/2，x）。

#### 牛顿法

牛顿法（姑且这么称呼）：

根据牛顿的理论

对于多项式 P（x） = a*(x^n)+b*(x^(n-1))+c*(x^(n-2))······

若存在近似值r，使得P（r）≈ 0，那么 r - P(r)/P'(r) 的值将比 r 更加接近 真实解 的值。

那么如何使用呢？

对于求24的平方根，我们可以设P(x)=x^2 - 24,那么P‘(x) = 2*x

这样对于近似值r，设置r = r - (r^2-24)/2*r，这样不断迭代，就可以更加快速地得到近似值。

### 计算机如何计算e^x

e^x=1+x+(x2)/(2!)+(x3)/(3!)+(x4)/(4!)+…+(x^n)/n!

### 计算机如何计算三角函数

利用泰勒公式计算如


$$
sinx=\sum_{k=0}^{\infty}\frac{(−1)^k}{(2k+1)!}x^{2k+1}=x−\frac{1}{3!}x^3+\frac{1}{5!}x^5−\frac{1}{7!}x^7+⋯\\
cosx=\sum_{k=0}^∞\frac{(-1)^k}{(2k)!}x^{2k}=1−\frac{1}{2!}x^2+\frac{1}{4!}x^4−\frac{1}{6!}x^6+⋯
$$

### c/c++ 有什么区别

C语言的编程方式是一种称为面 向过程的开发方式。也就是说，解决问题的时候，程序员需要思考计算机应该如何一步一步完成这个问题，然后将相应过程转化为代码。

有人在C语言的基础上添加了面向对象的功能，就是C++.同时，C++修改了C语言中一些不方便的规 定，使C语言用起来更方便了。C++是在C语言的基础上发展来的，但是并不是C++比C语言高级，两者的编程思想不一样

，全新的程序程序思维，C语言是面向过程的，而C＋＋是面向对象的。

2，C语言有标准的函数库，它们松散的，只是把功能相同的函数放在一个头文件中；而C++对于大多数的函数都是有集成的很紧密，特别是C语言中没有的C++中的API是对Window系统的大多数API有机的组合，是一个集体。但你也可能单独调用API。

3，特别是C++中的图形处理，它和语言的图形有很大的区别。C语言中的图形处理函数基本上是不能用在中C++中的。C语言标准中不包括图形处理。



### 如何理解面向对象和面向过程程序设计

#### 面向对象

就是看事物的一种方式，一种视觉角度，分析方式，我们可以把任意一个事物看成是一个对象，分析它身上具备的主要特征，这个就是面向对象思维；也就是分析主体，宏观分析

是把构成问题事务分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个事物在整个解决问题的步骤中的行为

适用于大型复杂系统，方便复用，但是比较抽象，难以理解

特点：封装 继承 

封装的意义：

封装的意义在于保护或者防止代码（数据）被我们无意中破坏。

保护成员属性，不让类以外的程序直接访问和修改；

隐藏方法细节

继承的意义：

主要实现重用代码，节省开发时间。

#### [面向过程](https://www.baidu.com/s?wd=面向过程&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)

就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了

 算法+数据结构

适用于简单系统，容易理解但难以应对复杂系统，难以复用

面向过程就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了；面向对象是把构成问题事务分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个事物在整个解决问题的步骤中的行为。

**1.** ***\*面向对象程序设计和面向过程程序设计的区别是什么？分别有什么利弊？\****

***\*【面向过程的程序设计】\****

面向过程的程序设计的核心是过程（流水线式思维), 过程即解决问题的步骤，面向过程的设计就好比精心设计好一条流水线，考虑周全什么时候处理什么东西。

***\*优点是\****：极大的降低了写程序的复杂度，只需要顺着要执行的步骤，堆叠代码即可。流程化使得编程任务明确，在开发之前基本考虑了实现方式和最终结果，具体步骤清楚，便于节点分析。***\*效率高\****，面向过程强调代码的短小精悍，善于结合数据结构来开发高效率的程序。

***\*缺点是\****：一套流水线或者流程就是用来解决一个问题，代码牵一发而动全身。需要深入的思考，耗费精力，代码重用性低，扩展能力差，后期维护难度比较大。

***\*应用场景\****：一旦完成基本很少改变的场景，著名的例子有Linux內核，git，以及Apache HTTP Server等。

***\*【面向对象的程序设计】\****

***\*优点是：\*******\*解决了程序的扩展性\****。对某一个对象单独修改，会立刻反映到整个体系中，如对游戏中一个人物参数的特征和技能修改都很容易。***\*结构清晰\****，程序是模块化和结构化，更加符合人类的思维方式；***\*易扩展\****，代码重用率高，可继承，可覆盖，可以设计出低耦合的系统；***\*易维护\****，系统低耦合的特点有利于减少程序的后期维护工作量。

***\*缺点是：\*******\*可控性差\****，无法向面向过程的程序设计流水线式的可以很精准的预测问题的处理流程与结果，面向对象的程序一旦开始就由对象之间的交互解决问题，即便是上帝也无法预测最终结果。***\*开销大\****，当要修改对象内部时，对象的属性不允许外部直接存取，所以要增加许多没有其他意义、只负责读或写的行为。这会为编程工作增加负担，增加运行开销，并且使程序显得臃肿。***\*性能低\****，由于面向更高的逻辑抽象层，使得面向对象在实现的时候，不得不做出性能上面的牺牲，计算时间和空间存储大小都开销很大。

***\*应用场景：\****需求经常变化的软件，一般需求的变化都集中在用户层，互联网应用，企业内部软件，游戏等都是面向对象的程序设计大显身手的好地方。

![img](D:\note\相关图片\wps1.jpg) 

####  高内聚，低耦合的意义

 高内聚，低耦合是相对于代码而言，一个项目中：

每个模块之间相互联系的紧密程度，模块之间联系越紧密，则耦合性越高，模块的独立性就越差！反之同理；

一个模块中各个元素之间的联系的紧密程度，如果各个元素（语句、程序段）之间的联系程度越高，则内聚性越高，即‘高内聚’ ！

如: 一个项目中有20个方法调用良好，但是要修改了其中一个，另外的19个都要进行修改，这就是高耦合！独立性太差！

现在的软件结构设计，都会要求“高内聚，低耦合”，来保证软件的高质量

### 介绍一个你所了解的AI概念

#### AI：Artificial Intelligence，人工智能。

利用计算机来对人的意识、思维信息过程、智能行为进行模拟（如学习、推理、思考、规划等）和延伸，使计算机能实现更高层次的应用。

#### ML：Machine Learning，机器学习。

从数据中学习的AI叫做机器学习。机器学习是指从一系列的原始数据中提取人们可以识别的特征，然后通过学习这些特征，最终产生一个模型。

#### DL：Deep Learning，深度学习。

机器学习的一个子集，用复杂、庞大的神经网络进行机器学习，也是机器学习里面现在比较火的一个Topic，目前在图像，语音等富媒体的分类和识别上取得了非常好的效果

#### **生物识别**

通过计算机，与光学、声学、生物传感器、统计学的概念手段结合，利用人体固有的生理特性和行为特征进行个人身份的鉴定。

通常意义的生物识别，包含了指纹识别，人脸识别，视网膜识别，虹膜识别，甚至还有掌纹识别。

###  计算机语言cnn,nlp,rnn分别指什么

#### 自然语言处理（Natural Language Processing，NLP）

是指让计算机接受用户自然语言形式的输入，并在内部通过人类所定义的算法进行加工、计算等系列操作，以模拟人类对自然语言的理解，并返回用户所期望的结果。自然语言处理的目的在于用计算机代替人工来处理大规模的自然语言信息。在很大程度上与计算语言学（Computational Linguistics，CL）重合，是计算机科学与语言学的交叉学科，也是人工智能的重要方向。自然语言处理的研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。让计算机能够确切理解人类的语言，并自然地与人进行交互是NLP的最终目标。

自然语言处理的挑战通常涉及语音识别、自然语言理解和自然语言生成。

#### **循环神经网络**，**Recurrent Neural Network**（rnn）。

神经网络是一种节点定向连接成环的[人工神经网络](https://baike.sogou.com/lemma/ShowInnerLink.htm?lemmaId=145633953&ss_c=ssc.citiao.link)。这种网络的内部状态可以展示动态时序行为。不同于[前馈神经网络](https://baike.sogou.com/lemma/ShowInnerLink.htm?lemmaId=76472726&ss_c=ssc.citiao.link)的是，RNN可以利用它内部的记忆来处理任意时序的输入序列，这让它可以更容易处理如不分段的手写识别、语音识别等。

#### **CNN的全称是"Convolutional Neural Network"(卷积神经网络)。**

**而神经网络是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）结构和功能的数学模型或计算模型。**神经网络由大量的人工神经元组成，按不同的连接方式构建不同的网络。CNN是其中的一种，

###  电脑死机有哪些原因？

散热不良，机器内部器件松动导致接触不良，机器内灰尘过多，设备不匹配（主板主频和CPU主频不匹配），供电不足，软硬件不兼容，内存条松动，CPU超频，硬盘老化，操作系统与硬件不兼容，内存不够

病毒感染，软件升级不当，启动的程序太多，非正常关闭计算机

### 电脑运行慢有哪些原因？基本同上

### 计算机有哪些构件组成

计算机的主要组成部分可以归纳为以下五个部分：

#### 1、控制器：

是整个计算机的中枢神经，其功能是对程序规定的控制信息进行解释，根据其要求进行控制，调度程序、数据、地址，协调计算机各部分工作及内存与外设的访问等。

#### 2、运算器：

对数据进行各种算术运算和逻辑运算，即对数据进行加工处理。

#### 3、存储器：

是存储程序、数据和各种信号、命令等信息，并在需要时提供这些信息。

#### 4、输入设备：

是计算机的重要组成部分，输入设备与输出设备合你为外部设备，简称外设，输入设备的作用是将程序、原始数据、文字、字符、控制命令或现场采集的数据等信息输入到计算机。

#### 5、输出设备：

把外算机的中间结果或最后结果、机内的各种数据符号及文字或各种控制信号等信息输出出来。微机常用的输出设备有打印机、激光印字机、绘图仪及磁带、光盘机等。

### 经典的计算机架构是怎么样的？

#### 冯诺依曼理论

要点是：数字计算机的数制采用二进制；计算机应该按照程序顺序执行。 
　　其主要内容是： 
　　1.计算机由控制器、运算器、存储器、输入设备、输出设备五大部分组成。 
　　2.程序和数据以二进制代码形式不加区别地存放在存储器中，存放位置由地址确定。 
　　3.控制器根据存放在存储器中地指令序列（程序）进行工作，并由一个程序计数器控制指令地执行。控制器具有判断能力，能根据计算结果选择不同的工作流程。 
　　人们把冯诺依曼的这个理论称为冯诺依曼体系结构。从ENIAC到当前最先进的计算机都采用的是冯诺依曼体系结构。所以冯诺依曼是当之无愧的数字计算机之父。 
　　根据冯诺依曼体系结构构成的计算机，必须具有如下功能： 
　　把需要的程序和数据送至计算机中。 
　　必须具有长期记忆程序、数据、中间结果及最终运算结果的能力。 
　　能够完成各种算术、逻辑运算和数据传送等数据加工处理的能力。 
　　能够根据需要控制程序走向，并能根据指令控制机器的各部件协调操作。 
　　能够按照要求将处理结果输出给用户。 
　　为了完成上述的功能，计算机必须具备五大基本组成部件，包括： 
　　输入数据和程序的输入设备； 
　　记忆程序和数据的存储器； 
　　完成数据加工处理的运算器； 
　　控制程序执行的控制器； 
　　输出处理结果的输出设备 。 

计算机科学中的理论部分在第一台数字计算机出现以前就已存在。

计算机科学根植于电子工程、数学和语言学，是科学、工程和艺术的结晶。它在20世纪最后的三十年间兴起成为一门独立的学科，并发展出自己的方法与术语。



**编程分为硬件编程和软件编程。**

先由硬件编程讲起（零基础者必须了解，了解有助于认识编程，）中央处理器又叫cpu，（这里用大白话讲述），cpu有很多向外的线 （术语叫做引脚），它们中有一根线我们以它作为电压0参考，其余的线有两个功能：1.读出这点接入的电路的电压，2.输出电压我们又定义电压U，以U为界限将读取输入的电压分为0,1。在PC，笔记本电脑上，1指电压低于-12V，手机里1指电压高于3V，其他情况为零。对于一块1600万色的屏幕，它可以显示16777216（就是24个2相乘）中颜色，24根线每根线电压为0或1，那么刚好有16777216组合，屏幕会根据每根线的电压大小判断该显示的颜色，对1080P的屏幕有1920*1080个点即2073600（小于21个2相乘），21根线的组合可以涵盖屏幕上的点，显示时，21根线告诉屏幕那一个点亮，24根线告诉屏幕亮什么颜色，当21根线代表的点不是这一点，这一点颜色不会变化，拿小米电视来说1s一个点最多可以改变30次，超过24次人眼就感觉不出来。

下面是大家关心的，软件编程，大多数人想编的是在windows上运行的。

现在软件编程包括windows编程，安卓编程，OX编程，linux编程。先讲一下原理。拿windows编程来说，微软公司用C语言编写了能使intel amd的cpu驱动显示器显示的程序，就是windows操作系统，你要编写的程序写完后告诉windows，windows把你写的程序当作想点数标一样的反应。微软自己定义了一套语言，但是开发者学习成本有很高，C语言模拟器又满足不了它的要求，于是微软开发了C#（C#有着与C相同的结构赋值规则），它是专门为windows设计的语言，又是windows开发环境，C#最大化的减少windows开发难度，同时增大不同人间的协作性，WPS、AE、QQ影音都是用C#编出的，只要你学过C语言和C#你就可以在windows平台开发。最后说一下JAVA，随着图形界面的流行，各个系统操作日益相同，如windows，linux，MAC OS，java应运而生，它可以把你写的程序翻译为相似平台的语言，从而在各个平台运行。初学者自学不要碰JAVA，只有学过C语言，C#你才能看的懂。

最后总结一下：

**编程首先要学C语言（可以不学C++），数据结构（当编写大程序如wps，学过数据结构能增加运行速度，不学的话也可以）这两者可以让你明白编程的基本规则。**



### 计算机快捷键

| F1               | 显示程序或系统帮助内容 |
| ---------------- | ---------------------- |
| F2               | 重新命名所选项目       |
| F3               | 搜索文件或文件夹       |
| F5               | 刷新当前窗口           |
| F6               | 循环切换屏幕元素       |
| F10              | 激活当前程序中的菜单条 |
| Ctrl+A           | 选中全部内容           |
| Ctrl+C           | 复制                   |
| Ctrl+X           | 剪切                   |
| Ctrl+V           | 粘贴                   |
| Ctrl+Z           | 撤消                   |
| Ctrl+Esc         | 显示“开始”菜单         |
| Alt+Enter        | 查看所选项目的属性     |
| Alt+F4           | 关闭当前项目或退出程序 |
| Alt+空格键       | 为当前窗口打开快捷菜单 |
| Alt+Tab          | 打开项目间切换         |
| Alt+Esc          | 项目打开顺序循环切换   |
| Delete           | 删除                   |
| Shift+Delete     | 永久删除所选项         |
| Shift+F10        | 显示所选项快捷菜单     |
| Esc              | 取消当前任务           |
| Ctrl+Alt+Delet   | 电脑锁屏               |
| PrintScreenSysRq | 电脑截图               |
| Ctrl+Alt+A       | qq截图                 |
| Ctrl+Shift+X     | 搜狗浏览器截图         |
|                  |                        |

### 计算机是不是科学

#### 所谓科学就是提出假设，然后在现实世界中创建模型，通过各种实验得到真理。（约翰.沃诺克）

##### 计算机之所以有资格被称为科学的一个重要原因是它有一个扎实的理论基础。

计算机理论主要有三个方面组成：可计算性理论、复杂性理论和计算机算法设计与分析。这让当代计算机所有应用领域都有了坚实的地基。

在其发展过程中，有两个人做出了巨大的贡献：一个是大家熟知的图灵（Alan Turing），计算机界的图灵奖等同于诺贝尔奖，可见其地位了。而另一位是大家不太熟悉，目前执教于加拿大多伦多大学的史提芬·古克（Stephen A. Cook），也是图灵奖的获得者。（以后我会介绍一些这两人的故事。）

图灵的工作提出并回答了可计算性的问题，他把世界上的问题分成了两类，一类是计算机可以解决的，也就是可计算的；一类是计算机不可解决的，也就是不可计算的。许多人以为计算机可以解决一切问题，其实不然。世界上有大量问题是计算机无法解决的。图灵在1936年证明了第一个不可计算的问题（文章发表于1937年）：停机问题。停机问题是个判定问题，对任何程序和给定的输入，这个程序是否会最终停止运行。图灵证明了能够判定这个问题的程序是不存在的，也就是说停机问题是不可计算的。

#### 

### 怎么理解指针

指针存储了变量的地址，直接访问内存单元，在进行改变指针时，其实就是到达变量的地址然后直接改变存储的变量的值，改变了指针也就是改变了存储的变量

指针的缺点是不安全。因为如果指针数据被恶意写入一些特定的值，便会出现很多的问题。有可能不想被用户知道的存在于内存中的数据将被指针调用。有可能恶意用户可以通过指针向特定内存单元写入特定的数据，造成缓冲区溢出等等的问题。 造成的后果将有可能是重要数据被窃取，甚至使恶意用户获得系统的高级权限。

并且有些量我们并不想让它改变。

a=b;这是间接改变变量，因为b要先到达a变量的地址，再将b的值赋予a，而指针是直接改变变量a的值，没有赋予的过程。

### 假如有一个序列，已知其中一个数出现的次数超过50%，请你找出这个数

#### 1.快速排序方法

运用快速排序，让序列的数字进行排序，则出现次数超过50%的数一定在中位数也就是位于n/2位置的那个数,时间复杂度也就是O(NlogN)

#### 2.桶排序方法

如果数的大小跨度很大，就先将数离散化，再开一个数组，让1对应1，1000000对应2这类，然后利用桶排序记录每个数出现的次数，时间复杂度也就是O(N+M)

#### 3.结合的排序方法

选择一个数作为划分起点，然后用类似快速排序的方法将小于它的移动到左边，大于它的移动到右边，此时划分点所在位置为k，如果k>n/2,那么继续用同样的方法在左边找，如果k<n/2就在右边部分找，k=n/2那么就是这个数，时间复杂度近似于O(N)

#### 4.更好的办法

这样的序列有一个特性：在原序列中去除两个不同的数，那么在原序列中出现次数超过50%的数，在新序列中出现次数也一定超过50%。

那么只要一直去除两个不相同的数直到序列中数的个数较少比如4个，然后再对数字的个数进行计数此时个数大于等于50%的数就是我们要找的数。

### 计算机内部结构与物理相关

计算机内部是由  IC（集成电路）这种电子部件构成的，CPU（微处理器）和内存也是 IC 的一种。IC 的所有引脚，只有直流电压0V 或 5V B 两个状态。也就是说，IC 的一个引脚，只能表示两个状态。IC 的这个特性，决定了计算机的信息数据只能用二进制数来处理。，所以二进制的计数方式就变成了 0、1、10、11、100…这种形式。学习大学物理能使我们了解计算机是如何通过二进制进行处理信息的，以及为什么计算机要用二进制来处理信息。

### 计算机为什么算小数时可能会算错

计算机是以二进制进行计算的。有些十进制小数是不能用有限位数的二进制小数表示的，由于计算机无法精确表示某些十进制小数，所以在进行计算时小数部分可能算错。

一个小数，我们可以写成如下形式

![img](D:\note\相关图片\20190626173508428.png)

基数是2，所以可以省略

双精度用64位比特二进制，分别来表示符号、尾数、基数和指数，而单精度用32位。

![img](D:\note\相关图片\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvbmdnYW56aGUwMg==,size_16,color_FFFFFF,t_70.png)

#### 有什么解决办法吗：

①对于精度不高的，忽略就行，反正误差也不大
②对于精度高的，Java有BigDecimal类
③化成整数，比如要算100个0.1相加，可以算100个1相加，再除以10

### 如何告诉操作系统打开文件呢？

看似简单的操作到底层都非常复杂，打开文件首先要扫描硬盘，找到文件的位置，然后从文件中读取一部分数据，将数据放进I/O缓冲区，放进内存；这些数据都是0、1序列，还要对照ASCII表或Unicode表”翻译“成字符，再在显示器上显示出来。

别人写好的代码，或者编译好的程序，提供给你使用，就叫做API（***\*即应用程序编程接口。\****）。你使用了别人代码（或者程序）中的某个函数、类、对象，就叫做使用了某个API。